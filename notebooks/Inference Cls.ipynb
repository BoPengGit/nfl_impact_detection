{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *\n",
    "from utils.plot import visualize_preds_indexed, visualize_preds\n",
    "from utils.metrics import boxes_f1_score, precision_calc, get_boxes_from_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA_PATH + 'df_train.csv')\n",
    "folds = pd.read_csv(OUT_DIR + \"folds.csv\")\n",
    "df_train = df_train.merge(folds, on=\"video\")\n",
    "df_train['truth'] = (df_train['impact'] == 1) & (df_train['confidence'] > 1) & (df_train['visibility'] > 0) \n",
    "\n",
    "\n",
    "df_val = df_train[df_train[\"val_idx\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = df_val['video'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDS_PATH = OUT_DIR + '21_12/'\n",
    "# epoch = 11\n",
    "# preds = pd.read_csv(PREDS_PATH + f\"pred_0_fold_epoch_{epoch}_score_001.csv\")\n",
    "\n",
    "PREDS_PATH = OUT_DIR + '22_12/'\n",
    "epoch = 9\n",
    "preds = pd.read_csv(PREDS_PATH + f\"pred_0_fold_epoch_{epoch}_score_001_aug.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds[preds['pred'] > 0.1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability thresholding\n",
    "THRESHOLD_PRED = 0.8\n",
    "\n",
    "# Adjacency post-processing\n",
    "NMS_THRESHOLD = 0.35\n",
    "THRESHOLD_IOU = 0.35\n",
    "MAX_DIST = 4\n",
    "MIN_CLUST_SIZE = 0\n",
    "\n",
    "# View post-processing\n",
    "MIN_DIST = 6\n",
    "\n",
    "# Impact post-processing\n",
    "MAX_FRAME_DIST = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = preds[preds['pred'] > THRESHOLD_PRED].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = pred_val.groupby('video').agg(list)['pred'][videos].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_boxes = get_boxes_from_df(df_val[df_val['truth'] == 1], videos)\n",
    "pred_boxes = get_boxes_from_df(pred_val, videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score = boxes_f1_score(pred_boxes, gt_boxes)\n",
    "\n",
    "print(f' -> CV score is {score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from post_processing.adjacency import post_process_adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_pp = pred_val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_pp = post_process_adjacency(\n",
    "    df_pred_pp,\n",
    "    threshold=THRESHOLD_IOU,\n",
    "    max_dist=MAX_DIST,\n",
    "    min_clust_size=MIN_CLUST_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_boxes_pp = get_boxes_from_df(df_pred_pp, videos)\n",
    "score = boxes_f1_score(pred_boxes_pp, gt_boxes)\n",
    "\n",
    "print(f' -> CV score is {score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.classifier import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = preds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['image_name'] = (df_pred['video'].str.replace('.mp4', '') + '_' +\n",
    "                              df_pred['frame'].apply(lambda x: f'{x:04d}') + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_vid = df_pred[df_pred[\"video\"] == df_pred['video'].unique()[1]]\n",
    "\n",
    "dataset = NFLDatasetClsInference(\n",
    "    df_pred_vid,\n",
    "    transforms=get_transfos_cls(train=False, visualize=True),\n",
    "    root=IMG_PATH_F,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     plt.imshow(dataset[i].numpy().transpose(1, 2, 0))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = df_pred[\"image_name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CP_FOLDER = \"../dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"efficientnet-b1\": {\n",
    "        \"name\": \"efficientnet-b1\",\n",
    "        \"num_classes\": 1,\n",
    "        \"k\": 5,\n",
    "    },\n",
    "    \"efficientnet-b2\": {\n",
    "        \"name\": \"efficientnet-b2\",\n",
    "        \"num_classes\": 1,\n",
    "        \"k\": 5,\n",
    "    },\n",
    "    \"efficientnet-b3\": {\n",
    "        \"name\": \"efficientnet-b3\",\n",
    "        \"num_classes\": 1,\n",
    "        \"k\": 5,\n",
    "    },\n",
    "    \"efficientnet-b4\": {\n",
    "        \"name\": \"efficientnet-b4\",\n",
    "        \"num_classes\": 1,\n",
    "        \"k\": 5,\n",
    "    },\n",
    "    \"resnet18\": {\n",
    "        \"name\": \"resnet18\",\n",
    "        \"num_classes\": 1,\n",
    "        \"k\": 5,\n",
    "    },\n",
    "    \"resnet34\": {\n",
    "        \"name\": \"resnet34\",\n",
    "        \"num_classes\": 1,\n",
    "        \"k\": 5,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for model in configs:\n",
    "    models += [retrieve_model(configs[model], fold=0, log_folder=CP_FOLDER)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for vid in tqdm(df_pred['video'].unique()):\n",
    "    df_pred_vid = df_pred[df_pred[\"video\"] == vid]\n",
    "\n",
    "    pred = inference(df_pred_vid, models, root=IMG_PATH_F)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['pred_cls'] = np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier with Aux inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference.classifier_aux import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CP_FOLDER = \"../dataset2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"efficientnet-b1\": {\n",
    "        \"name\": \"efficientnet-b1\",\n",
    "        \"num_classes\": 1,\n",
    "        \"num_classes_aux\": 4,\n",
    "        \"k\": 5,\n",
    "    },\n",
    "    \"efficientnet-b3\": {\n",
    "        \"name\": \"efficientnet-b3\",\n",
    "        \"num_classes\": 1,\n",
    "        \"num_classes_aux\": 4,\n",
    "        \"k\": 5,\n",
    "    },\n",
    "\n",
    "    \"resnet18\": {\n",
    "        \"name\": \"resnet18\",\n",
    "        \"num_classes\": 1,\n",
    "        \"num_classes_aux\": 4,\n",
    "        \"k\": 5,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for model in configs:\n",
    "    models += [retrieve_model_aux(configs[model], fold=0, log_folder=CP_FOLDER)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "preds_aux = []\n",
    "\n",
    "for vid in tqdm(df_pred['video'].unique()):\n",
    "    df_pred_vid = df_pred[df_pred[\"video\"] == vid]\n",
    "\n",
    "    pred, pred_aux = inference_aux(df_pred_vid, models, root=IMG_PATH_F)\n",
    "    \n",
    "    preds.append(pred)\n",
    "    preds_aux.append(pred_aux)\n",
    "    \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.concatenate(preds).flatten()\n",
    "preds_aux = np.concatenate(preds_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['pred_aux_helmet'] = preds_aux[:, 1]\n",
    "df_pred['pred_aux_body'] = preds_aux[:, 2]\n",
    "df_pred['pred_aux_ground'] = preds_aux[:, 3]\n",
    "\n",
    "impact_types = [\"helmet\", \"body\", \"ground\"]\n",
    "df_pred['predicted_impact_type'] = [impact_types[c] for c in np.argmax(preds_aux[:, 1:], 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df_pred['predicted_impact_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['pred_cls_aux'] = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from post_processing.adjacency import post_process_adjacency\n",
    "from post_processing.expansion import expand_boxes\n",
    "from post_processing.view import post_process_view\n",
    "from post_processing.pairing import post_process_pairing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD_DET = 0.5\n",
    "THRESHOLD_CLS = 0.5\n",
    "MIN_CLUST_SIZE = 0\n",
    "\n",
    "THRESHOLD_IOU = 0.35\n",
    "MAX_DIST = 4\n",
    "\n",
    "MIN_DIST = 5\n",
    "\n",
    "R = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_pp = df_pred.copy()\n",
    "df_pred_pp = df_pred_pp[df_pred_pp['pred'] > THRESHOLD_DET]\n",
    "df_pred_pp = df_pred_pp[df_pred_pp['pred_cls'] > THRESHOLD_CLS]\n",
    "df_pred_pp = df_pred_pp[df_pred_pp['pred_cls_aux'] > 0.25]\n",
    "\n",
    "# df_pred_pp = df_pred_pp[\n",
    "#     (df_pred_pp['pred_aux_helmet'] > 0.1) | (df_pred_pp['pred_aux_body'] > 0.1) | (df_pred_pp['pred_aux_ground'] > 0.1)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_boxes_pp = get_boxes_from_df(df_pred_pp, videos)\n",
    "score = boxes_f1_score(pred_boxes_pp, gt_boxes)\n",
    "\n",
    "print(f' -> CV score is {score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df_pred_pp[\"predicted_impact_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_pp = expand_boxes(df_pred_pp, r=R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjacency Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pred_pp = post_process_adjacency(\n",
    "    df_pred_pp,\n",
    "    threshold=THRESHOLD_IOU,\n",
    "    max_dist=MAX_DIST,\n",
    "    min_clust_size=MIN_CLUST_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred_pp= df_pred_pp[df_pred_pp['predicted_impact_type'] != \"ground\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_boxes_pp = get_boxes_from_df(df_pred_pp, videos)\n",
    "score = boxes_f1_score(pred_boxes_pp, gt_boxes)\n",
    "\n",
    "print(f' -> CV score is {score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df_pred_pp[\"predicted_impact_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MIN_DIST > 0:\n",
    "    df_pred_pp_view = post_process_view(\n",
    "        df_pred_pp, \n",
    "        min_dist=MIN_DIST,\n",
    "#         keep_ground=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_boxes_pp = get_boxes_from_df(df_pred_pp_view, videos)\n",
    "score = boxes_f1_score(pred_boxes_pp, gt_boxes)\n",
    "\n",
    "print(f' -> CV score is {score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(df_pred_pp_view[\"predicted_impact_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helmet impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = df_pred.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for video in df_pred_pp_view['video'].unique()[3:4]:\n",
    "#     df_vid = df_pred_pp_view[df_pred_pp_view['video'] == video]\n",
    "    \n",
    "#     df_vid_matched = post_process_helmet_impact(\n",
    "#         df_vid, \n",
    "#         candidates,\n",
    "#         alpha=10,\n",
    "#         max_box_dist=100,\n",
    "#         max_frame_dist=8, \n",
    "#         r=R,\n",
    "#         max_dist=50,\n",
    "#         cls_threshold=0.3,\n",
    "#         det_threshold=0.,\n",
    "#         verbose=1\n",
    "#     )\n",
    "    \n",
    "#     idx = 0\n",
    "#     frames = df_vid_matched['frame'].unique()\n",
    "#     for frame in frames:\n",
    "#         df_viz = df_vid_matched[df_vid_matched['frame'] == frame].reset_index(drop=True)\n",
    "#         plt.figure(figsize=(16, 8))\n",
    "#         visualize_preds_indexed(df_viz, 0, IMG_PATH_F, start_idx=idx)\n",
    "#         idx += len(df_viz)\n",
    "#         plt.axis(False)\n",
    "#         plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pred_pp_i = post_process_pairing(\n",
    "    df_pred_pp_view,\n",
    "    candidates,\n",
    "    alpha=10, \n",
    "    max_box_dist=50, \n",
    "    max_frame_dist=4, \n",
    "    r=R,\n",
    "    max_dist=40, \n",
    "    cls_threshold=0.,\n",
    "    det_threshold=0.3,\n",
    "    remove_unpaired=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_boxes_pp = get_boxes_from_df(df_pred_pp_i, videos)\n",
    "score = boxes_f1_score(pred_boxes_pp, gt_boxes)\n",
    "\n",
    "print(f' -> CV score is {score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Counter(df_pred_pp_i[\"predicted_impact_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match(df_video):\n",
    "    cols = ['frame', \"left\", \"width\", \"top\", \"height\"]\n",
    "    df_video['match'] = 0\n",
    "    \n",
    "    p_df = df_video[df_video['gt'] == 0].reset_index(drop=True)\n",
    "    t_df = df_video[df_video['gt'] == 1].reset_index(drop=True)\n",
    "\n",
    "    p = p_df[cols].values\n",
    "    t = t_df[cols].values\n",
    "    p[:, 2] += p[:, 1]\n",
    "    p[:, 4] += p[:, 3]\n",
    "    t[:, 2] += t[:, 1]\n",
    "    t[:, 4] += t[:, 3]\n",
    "    t = t[:, [0, 1, 3, 2, 4]]\n",
    "    p = p[:, [0, 1, 3, 2, 4]]\n",
    "\n",
    "    cost_matix, row_ind, col_ind = precision_calc(t, p, return_assignment=True)\n",
    "    \n",
    "    for i, j in zip(row_ind, col_ind):\n",
    "        if cost_matix[i, j] == 0:\n",
    "            p_df.loc[j, 'match'] = 1\n",
    "            t_df.loc[i, 'match'] = 1\n",
    "\n",
    "    return pd.concat([p_df, t_df], 0).drop_duplicates().sort_values('frame').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot import plot_bboxes_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_preds(df_pred, video_name, frame, root=\"\", truth_col=\"impact\", threshold_pred=0.7):\n",
    "    img = f\"{video_name[:-4]}_{frame:04d}.png\"\n",
    "    img = cv2.imread(root + img)\n",
    "\n",
    "    df = df_pred[df_pred[\"video\"] == video_name]\n",
    "    df = df[df[\"frame\"] == frame].reset_index(drop=True)\n",
    "\n",
    "    try:\n",
    "        boxes = df[[\"left\", \"width\", \"top\", \"height\"]].values\n",
    "    except KeyError:\n",
    "        boxes = df[[\"x\", \"w\", \"y\", \"h\"]].values\n",
    "\n",
    "    boxes[:, 1] += boxes[:, 0]\n",
    "    boxes[:, 3] += boxes[:, 2]\n",
    "    boxes = boxes[:, [0, 2, 1, 3]]\n",
    "\n",
    "    try:\n",
    "        labels = [f\"{l}\\n{s:.3f}\" for s, l in df[[\"pred\", \"predicted_impact_type\"]].values]\n",
    "    except KeyError:\n",
    "        labels = [f\"{s:.3f}\" for s in df[\"pred\"].values]\n",
    "        labels = [l if l != \"nan\" else \"\" for l in labels]\n",
    "\n",
    "    colors = []\n",
    "    if \"match\" in df.columns:\n",
    "        for truth, match in df[[\"gt\", \"match\"]].values:\n",
    "            if truth:\n",
    "                if match:\n",
    "                    colors.append(\"g\")\n",
    "                else:\n",
    "                    colors.append(\"r\")\n",
    "            else:\n",
    "                if match:\n",
    "                    colors.append(\"b\")\n",
    "                else:\n",
    "                    colors.append(\"orange\")\n",
    "    else:\n",
    "        for pred, truth in df[[\"pred\", truth_col]].values:\n",
    "            if truth:\n",
    "                if pred > threshold_pred:\n",
    "                    colors.append(\"g\")\n",
    "                else:\n",
    "                    colors.append(\"r\")\n",
    "            else:\n",
    "                colors.append(\"b\")\n",
    "\n",
    "    plot_bboxes_pred(img, boxes, labels, colors)\n",
    "    plt.title(f\"Video {video_name} - frame {frame}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_pred_pp_i.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truth = df_val[df_val['truth'] == 1]\n",
    "df_truth = df_truth.rename(columns={\"x\": \"left\", \"w\": \"width\", \"y\": \"top\", \"h\":\"height\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, vid in enumerate(df_results['video'].unique()):\n",
    "    df_vid_pred = df_results[df_results['video'] == vid].copy()\n",
    "    df_vid_truth = df_truth[df_truth['video'] == vid].copy()\n",
    "    df_vid_truth['gt'] = 1\n",
    "    df_vid_pred['gt'] = 0\n",
    "    \n",
    "    df_vid = pd.concat([df_vid_truth, df_vid_pred])\n",
    "    df_vid = get_match(df_vid)\n",
    "    \n",
    "    frames = sorted(df_vid['frame'].unique())\n",
    "    for frame in frames:\n",
    "        df_viz = df_vid[df_vid['frame'] == frame].reset_index(drop=True)\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        \n",
    "        visualize_preds(\n",
    "            df_vid, \n",
    "            vid, \n",
    "            frame, \n",
    "            root=IMG_PATH_F, \n",
    "            truth_col=\"truth\",\n",
    "        )\n",
    "\n",
    "        plt.axis(False)\n",
    "        plt.show()\n",
    "\n",
    "    if idx > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
