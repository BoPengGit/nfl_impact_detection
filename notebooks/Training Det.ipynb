{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cropping to focus on players\n",
    "- detect wide views and use crops for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA_PATH + 'df_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_impacts = df_train[[\"image_name\", \"extended_impact\"]].groupby('image_name').max().reset_index()\n",
    "frame_impacts = frame_impacts.rename(columns={\"extended_impact\": \"frame_has_impact\"})\n",
    "df_train = df_train.merge(frame_impacts, on=\"image_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train[df_train['frame_has_impact'] == 1]\n",
    "df_train['extended_impact'] += 1 \n",
    "df_train['impact'] +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = pd.read_csv(OUT_DIR + \"folds.csv\")\n",
    "df_train = df_train.merge(folds, on=\"video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = IMG_PATH_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"512\" in img_path:\n",
    "    df_train[\"x\"] = (df_train[\"x\"] / IMG_SHAPE[1] * SIZE).astype(int)\n",
    "    df_train[\"y\"] = (df_train[\"y\"] / IMG_SHAPE[0] * SIZE).astype(int)\n",
    "    df_train[\"w\"] = (df_train[\"w\"] / IMG_SHAPE[1] * SIZE).astype(int)\n",
    "    df_train[\"h\"] = (df_train[\"h\"] / IMG_SHAPE[0] * SIZE).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import NFLDatasetDet\n",
    "from data.transforms import get_transfos_det\n",
    "from utils.plot import plot_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = NFLDatasetDet(\n",
    "    df_train.copy(),\n",
    "    transforms=get_transfos_det(train=True, visualize=True),\n",
    "    root=img_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image, boxes, label, vid, frame = dataset[0]\n",
    "boxes = boxes.int()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plot_bboxes(image.numpy().transpose(1, 2, 0).copy(), boxes, label, transpose=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_zoo.models_det import get_model, get_val_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'tf_efficientdet_d0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = get_model(\n",
    "    name,\n",
    "    num_classes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NFLDatasetDet(\n",
    "    df_train,\n",
    "    transforms=get_transfos_det(train=True),\n",
    "    root=img_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, boxes, target = dataset[0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model(\n",
    "    image.unsqueeze(0),\n",
    "    boxes.unsqueeze(0),\n",
    "    target.unsqueeze(0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_model = get_val_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scales = torch.tensor([1]).long()\n",
    "\n",
    "pred_val = val_model(\n",
    "    image.unsqueeze(0),\n",
    "    scales\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.main_det import k_fold_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logger import prepare_log_folder, save_config, create_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZES = {\n",
    "    \"tf_efficientdet_d0\": 12,\n",
    "    \"tf_efficientdet_d1\": 8,\n",
    "#     \"tf_efficientdet_d2\": 8,\n",
    "    \"tf_efficientdet_d3\": 6,\n",
    "    \"tf_efficientdet_d4\": 4,\n",
    "    \"tf_efficientdet_d5\": 2,\n",
    "    \"tf_efficientdet_d6\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Parameters used for training\n",
    "    \"\"\"\n",
    "    # General\n",
    "    seed = 42\n",
    "    verbose = 1\n",
    "    img_path = img_path\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    save_weights = True\n",
    "\n",
    "\n",
    "    # k-fold\n",
    "    k = 5\n",
    "    random_state = 0\n",
    "    selected_folds = [0] # , 1, 2, 3, 4\n",
    "\n",
    "    # Model\n",
    "    name = \"tf_efficientdet_d4\"\n",
    "    num_classes = 1\n",
    "\n",
    "    # Training        \n",
    "    optimizer = \"Adam\"\n",
    "    batch_size = BATCH_SIZES[name]  # TODO : VERIF ACC STEPS\n",
    "    acc_steps = 1\n",
    "    epochs = 15\n",
    "    swa_first_epoch = 20\n",
    "\n",
    "    lr = 5e-4  # 5e-4 / 1e-3\n",
    "    warmup_prop = 0.05\n",
    "    val_bs = batch_size * 2\n",
    "    \n",
    "    first_epoch_eval = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "log_folder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if not DEBUG:\n",
    "    log_folder = prepare_log_folder(LOG_PATH)\n",
    "    print(f'Logging results to {log_folder}')\n",
    "    config_df = save_config(Config, log_folder + 'config.json')\n",
    "    create_logger(directory=log_folder, name=\"logs.txt\")\n",
    "\n",
    "meter = k_fold_det(\n",
    "    Config,\n",
    "    df_train,\n",
    "    log_folder=log_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.save import load_pickle\n",
    "from utils.metrics import iou_score\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA_PATH + 'df_train.csv')\n",
    "df_train['extended_impact'] += 1 \n",
    "df_train['impact'] +=1 \n",
    "folds = pd.read_csv(OUT_DIR + \"folds.csv\")\n",
    "df_train = df_train.merge(folds, on=\"video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder = \"../logs/2020-12-15/0/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter = load_pickle(log_folder + \"meter_0.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NFLDatasetDet(\n",
    "    df_train.iloc[meter.val_idx],\n",
    "    transforms=ToTensorV2(),\n",
    "    root=IMG_PATH_F,\n",
    ")\n",
    "\n",
    "vids = list(np.unique(df_train.iloc[meter.val_idx]['video']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_helmet, truths_helmet, preds_impact, _ = meter.get_helmets(helmet_threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TOT = 0\n",
    "DET = 0\n",
    "PLOT = True\n",
    "\n",
    "# for idx in np.random.choice(len(dataset), 1000):\n",
    "for idx in tqdm(range(len(dataset))):\n",
    "    image, boxes, label, vid, frame = dataset[idx]\n",
    "    \n",
    "#     if \"Sideline\" in vid:\n",
    "#         continue\n",
    "        \n",
    "    boxes = boxes.int()\n",
    "\n",
    "    boxes_pred = preds_helmet[vids.index(vid + \".mp4\")]\n",
    "    boxes_pred = boxes_pred[:, 1:][boxes_pred[:, 0] == frame]\n",
    "    label_pred = [1] * len(boxes_pred)\n",
    "    \n",
    "    boxes_pred[:, 0] = boxes_pred[:, 0] * IMG_SHAPE[1] / SIZE\n",
    "    boxes_pred[:, 1] = boxes_pred[:, 1] * IMG_SHAPE[0] / SIZE\n",
    "    boxes_pred[:, 2] = boxes_pred[:, 2] * IMG_SHAPE[1] / SIZE\n",
    "    boxes_pred[:, 3] = boxes_pred[:, 3] * IMG_SHAPE[0] / SIZE\n",
    "    boxes_pred = boxes_pred.astype(int)\n",
    "    \n",
    "    total, detected = 0, 0\n",
    "    for b in boxes[label == 2]:\n",
    "        total += 1\n",
    "        box = b.numpy()[np.array([1, 0, 3, 2])]\n",
    "        for i in range(len(boxes_pred)):\n",
    "            iou = iou_score(box, boxes_pred[i])\n",
    "            if iou > 0.35:\n",
    "                label_pred[i] = 2\n",
    "                detected += 1\n",
    "                break\n",
    "\n",
    "    TOT += total\n",
    "    DET += detected\n",
    "    \n",
    "    if PLOT and total != detected:\n",
    "        if label.max() == 2:\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plot_bboxes(image.numpy().transpose(1, 2, 0).copy(), boxes, label, transpose=True)\n",
    "            plt.title('Truth')\n",
    "            plt.axis(False)\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plot_bboxes(image.numpy().transpose(1, 2, 0).copy(), boxes_pred, label_pred, transpose=False)\n",
    "            plt.title('Pred')\n",
    "            plt.axis(False)\n",
    "            plt.show()\n",
    "\n",
    "            print(f'Detected {detected} / {total} helmets with impacts')\n",
    "    \n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOT, DET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def included(box, big_box, margin=10):\n",
    "    return ((box[0] - margin) > big_box[0] and \n",
    "            (box[1] - margin) > big_box[1] and \n",
    "            (box[2] + margin) < big_box[2] and \n",
    "            (box[3] + margin) < big_box[3]\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_crop(boxes, size=512, img_shape=(720, 1280), margin=10, plot=False, image=None):\n",
    "    \"\"\"\n",
    "    boxes : (x0, y0, x1, y1)\n",
    "    \"\"\"\n",
    "    min_x = max(0, np.min(boxes[:, 0]) - margin)\n",
    "    max_x = min(img_shape[1] - size, np.max(boxes[:, 2]) + margin)\n",
    "    min_y = max(0, np.min(boxes[:, 1]) - margin)\n",
    "    max_y = min(img_shape[0] - size, np.max(boxes[:, 3]) + margin)\n",
    "    \n",
    "    if min_x >= max_x:\n",
    "        min_x = 0\n",
    "        max_x = img_shape[1] - size\n",
    "    if min_y >= max_y:\n",
    "        min_y = 0\n",
    "        max_y = img_shape[0] - size\n",
    "    \n",
    "    best_count = 0\n",
    "    best_box = ()\n",
    "    for x in range(min_x, max_x, 10):\n",
    "        for y in range(min_y, max_y, 10):\n",
    "            box = np.array([x, y, x + size, y + size]).astype(int)\n",
    "            \n",
    "            count = np.sum([included(b, box, margin=margin) for b in boxes])\n",
    "            \n",
    "            if count > best_count:\n",
    "                best_box = box\n",
    "                best_count = count\n",
    "    \n",
    "    if not len(best_box):\n",
    "        print(min_x, max_x, min_y, max_y)\n",
    "        plot_bboxes(image.numpy().transpose(1, 2, 0).copy(), list(boxes), [1] * (len(boxes)))\n",
    "        plt.show()\n",
    "    \n",
    "    if plot and image is not None:\n",
    "        plot_bboxes(image.numpy().transpose(1, 2, 0).copy(), list(boxes) + [best_box], [1] * (len(boxes) + 1))\n",
    "        plt.title(best_count)\n",
    "        plt.show()\n",
    "\n",
    "    return best_box, best_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rois = []\n",
    "counts = []\n",
    "for idx in tqdm(range(len(dataset))):\n",
    "    image, boxes, label, vid, frame = dataset[idx]\n",
    "\n",
    "    boxes = boxes.int()\n",
    "\n",
    "    boxes_pred = preds_helmet[vids.index(vid + \".mp4\")]\n",
    "    boxes_pred = boxes_pred[:, 1:][boxes_pred[:, 0] == frame]\n",
    "    label_pred = [1] * len(boxes_pred)\n",
    "    \n",
    "    boxes_pred[:, 0] = boxes_pred[:, 0] * IMG_SHAPE[1] / SIZE\n",
    "    boxes_pred[:, 1] = boxes_pred[:, 1] * IMG_SHAPE[0] / SIZE\n",
    "    boxes_pred[:, 2] = boxes_pred[:, 2] * IMG_SHAPE[1] / SIZE\n",
    "    boxes_pred[:, 3] = boxes_pred[:, 3] * IMG_SHAPE[0] / SIZE\n",
    "    boxes_pred = boxes_pred.astype(int)\n",
    "    \n",
    "    roi, count = find_best_crop(boxes_pred, size=512, plot=(idx % 100) == 0, image=image)\n",
    "#     roi = find_best_crop(boxes_pred, size=512, plot=idx == 289, image=image)\n",
    "    rois.append(roi)\n",
    "    counts.append(count)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(log_folder + \"rois.npy\", np.array(rois))\n",
    "np.save(log_folder + \"counts.npy\", np.array(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
