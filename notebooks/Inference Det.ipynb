{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import NFLDatasetDet\n",
    "from data.transforms import get_transfos_det\n",
    "\n",
    "from utils.plot import plot_bboxes\n",
    "from utils.save import load_pickle\n",
    "from utils.torch import load_effdet_weights\n",
    "\n",
    "from model_zoo.models_det import get_inference_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA_PATH + 'df_train.csv')\n",
    "\n",
    "frame_impacts = df_train[[\"image_name\", \"extended_impact\"]].groupby('image_name').max().reset_index()\n",
    "frame_impacts = frame_impacts.rename(columns={\"extended_impact\": \"frame_has_impact\"})\n",
    "df_train = df_train.merge(frame_impacts, on=\"image_name\")\n",
    "\n",
    "# df_train = df_train[df_train['frame_has_impact'] == 1]\n",
    "df_train['extended_impact'] += 1 \n",
    "df_train['impact'] +=1 \n",
    "\n",
    "folds = pd.read_csv(OUT_DIR + \"folds.csv\")\n",
    "df_train = df_train.merge(folds, on=\"video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"512\" in IMG_PATH:\n",
    "    df_train[\"x\"] = (df_train[\"x\"] / IMG_SHAPE[1] * SIZE).astype(int)\n",
    "    df_train[\"y\"] = (df_train[\"y\"] / IMG_SHAPE[0] * SIZE).astype(int)\n",
    "    df_train[\"w\"] = (df_train[\"w\"] / IMG_SHAPE[1] * SIZE).astype(int)\n",
    "    df_train[\"h\"] = (df_train[\"h\"] / IMG_SHAPE[0] * SIZE).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP_FOLDER = LOG_PATH + \"2020-12-07/15/\"  # d3, best\n",
    "# CP_FOLDER = LOG_PATH + \"2020-12-08/3/\"  # d4\n",
    "# CP_FOLDER = LOG_PATH + \"2020-12-09/10/\"  # d4\n",
    "CP_FOLDER = LOG_PATH + \"2020-12-14/1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(CP_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_ref = load_pickle(CP_FOLDER + f'meter_{FOLD}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open(CP_FOLDER + f'config.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_inference_model(config['name'], config['num_classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = load_effdet_weights(model, CP_FOLDER + f'{config[\"name\"]}_{FOLD}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_train.iloc[meter_ref.val_idx].reset_index(drop=True)\n",
    "# games = df_val['gameKey'].unique()\n",
    "# df_val = df[df['gameKey'].apply(lambda x: x in games)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NFLDatasetDet(\n",
    "    df_val,\n",
    "    transforms=get_transfos_det(train=False),\n",
    "    root=IMG_PATH,\n",
    "    train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training.train import collate_fn\n",
    "from training.meter import NFLMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataset, batch_size, device=\"cuda\", num_classes=1):\n",
    "    model = model.eval().to(device)\n",
    "    \n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    meter = NFLMeter(num_classes=num_classes)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            images = torch.stack(batch[0]).to(device)\n",
    "            scales = torch.tensor([1] * len(images)).long().to(device)\n",
    "\n",
    "            y_pred = model(images, scales).detach()\n",
    "\n",
    "            meter.update(batch, y_pred) \n",
    "\n",
    "    return meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meter = predict(\n",
    "    model,\n",
    "    dataset,\n",
    "    config['val_bs'],\n",
    "    num_classes=config['num_classes']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_helmet, truths_helmet, preds_impact, t = meter.get_helmets(helmet_threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meter.compute_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact detection ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_helmet, _, _, truths_impact = meter.get_helmets(helmet_threshold=0.1, impact_threshold=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import detection_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_ratio(preds_helmet, truths_impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter.num_classes = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA_PATH + 'df_train.csv')\n",
    "\n",
    "frame_impacts = df_train[[\"image_name\", \"extended_impact\"]].groupby('image_name').max().reset_index()\n",
    "frame_impacts = frame_impacts.rename(columns={\"extended_impact\": \"frame_has_impact\"})\n",
    "df_train = df_train.merge(frame_impacts, on=\"image_name\")\n",
    "\n",
    "# df_train = df_train[df_train['frame_has_impact'] == 1]\n",
    "df_train['extended_impact'] += 1 \n",
    "df_train['impact'] +=1 \n",
    "\n",
    "folds = pd.read_csv(OUT_DIR + \"folds.csv\")\n",
    "df_train = df_train.merge(folds, on=\"video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_train.iloc[meter_ref.val_idx].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = np.load(CP_FOLDER + \"rois.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = get_transfos_det(train=False, visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import albumentations as albu\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "\n",
    "class NFLDatasetDetROI(Dataset):\n",
    "    def __init__(self, df, rois, root=\"\", transforms=None, train=False):\n",
    "        super().__init__()\n",
    "        self.train = train\n",
    "        self.root = root\n",
    "        self.rois = rois\n",
    "\n",
    "        self.transforms = transforms\n",
    "        self.bbox_params = albu.BboxParams(\n",
    "            format=\"pascal_voc\", min_area=0, min_visibility=0, label_fields=[\"labels\"]\n",
    "        )\n",
    "        \n",
    "        self.images = df.image_name.unique()\n",
    "        df = df.copy()\n",
    "        df['w'] += df['x']\n",
    "        df['h'] += df['y']\n",
    "        group = (\n",
    "            df[[\"image_name\", \"x\", \"y\", \"w\", \"h\", \"impact\", \"extended_impact\"]]\n",
    "            .groupby(\"image_name\")\n",
    "            .agg(list)\n",
    "            .reset_index()\n",
    "        )\n",
    "        self.images = group[\"image_name\"].values\n",
    "\n",
    "        if self.train:\n",
    "            self.labels = group['extended_impact'].values.tolist()\n",
    "        else:\n",
    "            self.labels = group['impact'].values.tolist()\n",
    "\n",
    "        self.boxes = group[['x', 'y', 'w', 'h']].values\n",
    "        self.boxes = [np.array(box.tolist()).T for box in self.boxes]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(f\"{self.root}/{self.images[idx]}\", cv2.IMREAD_COLOR)\n",
    "        boxes = self.boxes[idx]\n",
    "        labels = self.labels[idx]\n",
    "        roi = self.rois[idx]\n",
    "\n",
    "        frame = int(self.images[idx][-8:-4])\n",
    "        vid = self.images[idx][:-9]\n",
    "\n",
    "        transforms = albu.Compose([\n",
    "            albu.Crop(roi[0], roi[1], roi[2], roi[3]), \n",
    "            self.transforms,\n",
    "        ], bbox_params=self.bbox_params,)\n",
    "\n",
    "        sample = transforms(\n",
    "            **{\"image\": image, \"bboxes\": boxes, \"labels\": labels}\n",
    "        )\n",
    "        \n",
    "        image = sample[\"image\"]\n",
    "        labels = sample[\"labels\"]\n",
    "\n",
    "        boxes = torch.stack(\n",
    "            tuple(map(torch.tensor, zip(*sample[\"bboxes\"])))\n",
    "        ).permute(1, 0)\n",
    "\n",
    "        boxes[:, [0, 1, 2, 3]] = boxes[:, [1, 0, 3, 2]]  # (x, y), -> (y, x)\n",
    "\n",
    "        return image, boxes.float(), torch.tensor(labels), vid, frame, roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_roi_viz = NFLDatasetDetROI(\n",
    "    df_val.copy(), \n",
    "    rois, \n",
    "    transforms=get_transfos_det(train=False, visualize=True),\n",
    "    root=IMG_PATH_F\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in np.random.choice(len(dataset_roi_viz), 10):\n",
    "#     image, boxes, label, vid, frame, roi = dataset_roi_viz[i]\n",
    "#     boxes = boxes.int()\n",
    "\n",
    "#     plt.figure(figsize=(8, 8))\n",
    "#     plot_bboxes(image.numpy().transpose(1, 2, 0).copy(), boxes, label, transpose=True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_roi = NFLDatasetDetROI(\n",
    "    df_val.copy(), \n",
    "    rois, \n",
    "    transforms=get_transfos_det(train=False, visualize=False),\n",
    "    root=IMG_PATH_F\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_roi = predict(\n",
    "    model,\n",
    "    dataset_roi,\n",
    "    config['val_bs'],\n",
    "    num_classes=config['num_classes']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter_roi.compute_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.save import load_pickle\n",
    "from utils.metrics import iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids = list(np.unique(df_val['video']))\n",
    "preds_helmet, truths_helmet, preds_impact, _ = meter_roi.get_helmets(helmet_threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TOT = 0\n",
    "DET = 0\n",
    "PLOT = True\n",
    "\n",
    "# for idx in np.random.choice(len(dataset), 1000):\n",
    "for idx in tqdm(range(len(dataset_roi_viz))):\n",
    "    image, boxes, label, vid, frame, roi = dataset_roi_viz[idx]\n",
    "    \n",
    "#     if \"Sideline\" in vid:\n",
    "#         continue\n",
    "        \n",
    "    boxes = boxes.int()\n",
    "\n",
    "    boxes_pred = preds_helmet[vids.index(vid + \".mp4\")]\n",
    "    boxes_pred = boxes_pred[:, 1:][boxes_pred[:, 0] == frame]\n",
    "    label_pred = [1] * len(boxes_pred)\n",
    "    boxes_pred = boxes_pred.astype(int)\n",
    "    \n",
    "    total, detected = 0, 0\n",
    "    for b in boxes[label == 2]:\n",
    "        total += 1\n",
    "        box = b.numpy()[np.array([1, 0, 3, 2])]\n",
    "        for i in range(len(boxes_pred)):\n",
    "            iou = iou_score(box, boxes_pred[i])\n",
    "            if iou > 0.35:\n",
    "                label_pred[i] = 2\n",
    "                detected += 1\n",
    "                break\n",
    "\n",
    "    TOT += total\n",
    "    DET += detected\n",
    "    \n",
    "    if PLOT and total != detected:\n",
    "        if label.max() == 2:\n",
    "            plt.figure(figsize=(15, 7))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plot_bboxes(image.numpy().transpose(1, 2, 0).copy(), boxes, label, transpose=True)\n",
    "            plt.title('Truth')\n",
    "            plt.axis(False)\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plot_bboxes(image.numpy().transpose(1, 2, 0).copy(), boxes_pred, label_pred, transpose=False)\n",
    "            plt.title('Pred')\n",
    "            plt.axis(False)\n",
    "            plt.show()\n",
    "\n",
    "            print(f'Detected {detected} / {total} helmets with impacts')\n",
    "    \n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOT, DET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "257 / 415"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
